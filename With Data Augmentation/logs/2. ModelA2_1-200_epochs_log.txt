akshat@akshat:/media/akshat/Akshat/Linux Backup/deep_learning/Consolidated_Data_Set/gesture_recognition_with_augmentation/codes$ python 2.\ ModelA1_training.py
Using Theano backend.
Using gpu device 0: GeForce GTX 960M (CNMeM is disabled, cuDNN not available)
Found 259867 images belonging to 5 classes.
Found 86562 images belonging to 5 classes.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           zeropadding2d_input_1[0][0]      
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 64, 222, 222)  4864        zeropadding2d_1[0][0]            
____________________________________________________________________________________________________
zeropadding2d_2 (ZeroPadding2D)  (None, 64, 224, 224)  0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           zeropadding2d_2[0][0]            
____________________________________________________________________________________________________
zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 110, 110)  102464      zeropadding2d_3[0][0]            
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 55, 55)    0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
zeropadding2d_4 (ZeroPadding2D)  (None, 64, 57, 57)    0           maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 55, 55)   73856       zeropadding2d_4[0][0]            
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 128, 27, 27)   0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
zeropadding2d_5 (ZeroPadding2D)  (None, 128, 29, 29)   0           maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 27, 27)   295168      zeropadding2d_5[0][0]            
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 256, 13, 13)   0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 43264)         0           maxpooling2d_4[0][0]             
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          44303360    flatten_1[0][0]                  
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 1024)          0           dense_1[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1024)          1049600     dropout_1[0][0]                  
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 1024)          0           dense_2[0][0]                    
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 5)             5125        dropout_2[0][0]                  
====================================================================================================
Total params: 45834437
____________________________________________________________________________________________________
Epoch 1/50
2000/2000 [==============================] - 76s - loss: 1.6102 - acc: 0.2010 - val_loss: 1.6092 - val_acc: 0.2013
Epoch 2/50
2000/2000 [==============================] - 75s - loss: 1.6089 - acc: 0.2040 - val_loss: 1.6080 - val_acc: 0.2112
Epoch 3/50
2000/2000 [==============================] - 75s - loss: 1.6095 - acc: 0.2005 - val_loss: 1.6077 - val_acc: 0.1925
Epoch 4/50
2000/2000 [==============================] - 75s - loss: 1.6094 - acc: 0.2100 - val_loss: 1.6068 - val_acc: 0.2175
Epoch 5/50
2000/2000 [==============================] - 74s - loss: 1.6092 - acc: 0.2065 - val_loss: 1.6077 - val_acc: 0.2287
Epoch 6/50
2000/2000 [==============================] - 74s - loss: 1.6079 - acc: 0.2150 - val_loss: 1.6074 - val_acc: 0.2087
Epoch 7/50
2000/2000 [==============================] - 74s - loss: 1.6083 - acc: 0.2190 - val_loss: 1.6072 - val_acc: 0.2187
Epoch 8/50
2000/2000 [==============================] - 74s - loss: 1.6064 - acc: 0.2260 - val_loss: 1.6064 - val_acc: 0.2113
Epoch 9/50
2000/2000 [==============================] - 74s - loss: 1.6057 - acc: 0.2175 - val_loss: 1.6067 - val_acc: 0.1975
Epoch 10/50
2000/2000 [==============================] - 73s - loss: 1.6089 - acc: 0.2100 - val_loss: 1.6045 - val_acc: 0.2600
Epoch 11/50
2000/2000 [==============================] - 75s - loss: 1.6073 - acc: 0.2040 - val_loss: 1.6073 - val_acc: 0.1938
Epoch 12/50
2000/2000 [==============================] - 74s - loss: 1.6086 - acc: 0.2085 - val_loss: 1.6076 - val_acc: 0.2175
Epoch 13/50
2000/2000 [==============================] - 73s - loss: 1.6063 - acc: 0.2255 - val_loss: 1.6078 - val_acc: 0.2263
Epoch 14/50
2000/2000 [==============================] - 75s - loss: 1.6073 - acc: 0.2130 - val_loss: 1.6041 - val_acc: 0.2487
Epoch 15/50
2000/2000 [==============================] - 74s - loss: 1.6057 - acc: 0.2225 - val_loss: 1.6080 - val_acc: 0.2087
Epoch 16/50
2000/2000 [==============================] - 74s - loss: 1.6068 - acc: 0.2105 - val_loss: 1.6041 - val_acc: 0.2213
Epoch 17/50
2000/2000 [==============================] - 74s - loss: 1.6061 - acc: 0.2270 - val_loss: 1.6030 - val_acc: 0.2175
Epoch 18/50
2000/2000 [==============================] - 74s - loss: 1.6063 - acc: 0.2215 - val_loss: 1.6045 - val_acc: 0.2963
Epoch 19/50
2000/2000 [==============================] - 75s - loss: 1.6050 - acc: 0.2320 - val_loss: 1.6050 - val_acc: 0.1775
Epoch 20/50
2000/2000 [==============================] - 75s - loss: 1.6036 - acc: 0.2405 - val_loss: 1.6055 - val_acc: 0.2112
Epoch 21/50
2000/2000 [==============================] - 73s - loss: 1.6071 - acc: 0.2230 - val_loss: 1.6022 - val_acc: 0.2300
Epoch 22/50
2000/2000 [==============================] - 74s - loss: 1.6034 - acc: 0.2300 - val_loss: 1.6021 - val_acc: 0.2413
Epoch 23/50
2000/2000 [==============================] - 73s - loss: 1.6051 - acc: 0.2275 - val_loss: 1.5985 - val_acc: 0.2775
Epoch 24/50
2000/2000 [==============================] - 73s - loss: 1.6050 - acc: 0.2220 - val_loss: 1.5998 - val_acc: 0.2250
Epoch 25/50
2000/2000 [==============================] - 73s - loss: 1.6019 - acc: 0.2400 - val_loss: 1.6013 - val_acc: 0.2225
Epoch 26/50
2000/2000 [==============================] - 75s - loss: 1.6020 - acc: 0.2300 - val_loss: 1.5971 - val_acc: 0.2363
Epoch 27/50
2000/2000 [==============================] - 76s - loss: 1.5982 - acc: 0.2455 - val_loss: 1.5972 - val_acc: 0.2400
Epoch 28/50
2000/2000 [==============================] - 73s - loss: 1.6027 - acc: 0.2370 - val_loss: 1.5934 - val_acc: 0.2725
Epoch 29/50
2000/2000 [==============================] - 74s - loss: 1.5993 - acc: 0.2490 - val_loss: 1.5995 - val_acc: 0.2550
Epoch 30/50
2000/2000 [==============================] - 75s - loss: 1.6018 - acc: 0.2510 - val_loss: 1.5973 - val_acc: 0.2450
Epoch 31/50
2000/2000 [==============================] - 74s - loss: 1.5987 - acc: 0.2485 - val_loss: 1.5984 - val_acc: 0.2587
Epoch 32/50
2000/2000 [==============================] - 74s - loss: 1.5963 - acc: 0.2460 - val_loss: 1.5939 - val_acc: 0.2200
Epoch 33/50
2000/2000 [==============================] - 75s - loss: 1.5975 - acc: 0.2715 - val_loss: 1.5923 - val_acc: 0.2712
Epoch 34/50
2000/2000 [==============================] - 75s - loss: 1.5949 - acc: 0.2580 - val_loss: 1.5914 - val_acc: 0.2863
Epoch 35/50
2000/2000 [==============================] - 75s - loss: 1.5930 - acc: 0.2665 - val_loss: 1.5806 - val_acc: 0.3463
Epoch 36/50
2000/2000 [==============================] - 74s - loss: 1.5932 - acc: 0.2440 - val_loss: 1.5814 - val_acc: 0.2762
Epoch 37/50
2000/2000 [==============================] - 76s - loss: 1.5931 - acc: 0.2215 - val_loss: 1.5850 - val_acc: 0.2575
Epoch 38/50
2000/2000 [==============================] - 76s - loss: 1.5866 - acc: 0.2785 - val_loss: 1.5765 - val_acc: 0.3262
Epoch 39/50
2000/2000 [==============================] - 77s - loss: 1.5841 - acc: 0.2680 - val_loss: 1.5766 - val_acc: 0.2763
Epoch 40/50
2000/2000 [==============================] - 76s - loss: 1.5840 - acc: 0.2645 - val_loss: 1.5635 - val_acc: 0.3562
Epoch 41/50
2000/2000 [==============================] - 77s - loss: 1.5774 - acc: 0.2780 - val_loss: 1.5536 - val_acc: 0.3150
Epoch 42/50
2000/2000 [==============================] - 77s - loss: 1.5743 - acc: 0.2790 - val_loss: 1.5526 - val_acc: 0.2663
Epoch 43/50
2000/2000 [==============================] - 77s - loss: 1.5597 - acc: 0.3010 - val_loss: 1.5360 - val_acc: 0.3463
Epoch 44/50
2000/2000 [==============================] - 77s - loss: 1.5596 - acc: 0.2885 - val_loss: 1.5309 - val_acc: 0.3538
Epoch 45/50
2000/2000 [==============================] - 77s - loss: 1.5426 - acc: 0.3020 - val_loss: 1.5169 - val_acc: 0.3312
Epoch 46/50
2000/2000 [==============================] - 76s - loss: 1.5478 - acc: 0.3040 - val_loss: 1.5061 - val_acc: 0.3663
Epoch 47/50
2000/2000 [==============================] - 77s - loss: 1.5370 - acc: 0.2990 - val_loss: 1.4933 - val_acc: 0.3662
Epoch 48/50
2000/2000 [==============================] - 78s - loss: 1.5188 - acc: 0.3180 - val_loss: 1.4742 - val_acc: 0.4075
Epoch 49/50
2000/2000 [==============================] - 79s - loss: 1.5172 - acc: 0.3145 - val_loss: 1.4847 - val_acc: 0.3500
Epoch 50/50
2000/2000 [==============================] - 77s - loss: 1.4943 - acc: 0.3305 - val_loss: 1.4601 - val_acc: 0.3800
Saved model to disk

akshat@akshat:/media/akshat/Akshat/Linux Backup/deep_learning/Consolidated_Data_Set/gesture_recognition_with_augmentation/codes$ python 2.\ ModelA1_training.py
Using Theano backend.
Using gpu device 0: GeForce GTX 960M (CNMeM is disabled, cuDNN not available)
Found 259867 images belonging to 5 classes.
Found 86562 images belonging to 5 classes.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           zeropadding2d_input_1[0][0]      
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 64, 222, 222)  4864        zeropadding2d_1[0][0]            
____________________________________________________________________________________________________
zeropadding2d_2 (ZeroPadding2D)  (None, 64, 224, 224)  0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           zeropadding2d_2[0][0]            
____________________________________________________________________________________________________
zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 110, 110)  102464      zeropadding2d_3[0][0]            
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 55, 55)    0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
zeropadding2d_4 (ZeroPadding2D)  (None, 64, 57, 57)    0           maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 55, 55)   73856       zeropadding2d_4[0][0]            
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 128, 27, 27)   0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
zeropadding2d_5 (ZeroPadding2D)  (None, 128, 29, 29)   0           maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 27, 27)   295168      zeropadding2d_5[0][0]            
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 256, 13, 13)   0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 43264)         0           maxpooling2d_4[0][0]             
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          44303360    flatten_1[0][0]                  
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 1024)          0           dense_1[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1024)          1049600     dropout_1[0][0]                  
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 1024)          0           dense_2[0][0]                    
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 5)             5125        dropout_2[0][0]                  
====================================================================================================
Total params: 45834437
____________________________________________________________________________________________________
Weights loaded
Epoch 1/50
2000/2000 [==============================] - 68s - loss: 1.5087 - acc: 0.3110 - val_loss: 1.4276 - val_acc: 0.4175
Epoch 2/50
2000/2000 [==============================] - 68s - loss: 1.5000 - acc: 0.3235 - val_loss: 1.4298 - val_acc: 0.3662
Epoch 3/50
2000/2000 [==============================] - 68s - loss: 1.4755 - acc: 0.3475 - val_loss: 1.4094 - val_acc: 0.4013
Epoch 4/50
2000/2000 [==============================] - 68s - loss: 1.4865 - acc: 0.3275 - val_loss: 1.4238 - val_acc: 0.4225
Epoch 5/50
2000/2000 [==============================] - 69s - loss: 1.4683 - acc: 0.3615 - val_loss: 1.4037 - val_acc: 0.3987
Epoch 6/50
2000/2000 [==============================] - 68s - loss: 1.4684 - acc: 0.3450 - val_loss: 1.4030 - val_acc: 0.4113
Epoch 7/50
2000/2000 [==============================] - 68s - loss: 1.4566 - acc: 0.3610 - val_loss: 1.3733 - val_acc: 0.4400
Epoch 8/50
2000/2000 [==============================] - 70s - loss: 1.4328 - acc: 0.3775 - val_loss: 1.3853 - val_acc: 0.3900
Epoch 9/50
2000/2000 [==============================] - 68s - loss: 1.4095 - acc: 0.3900 - val_loss: 1.3267 - val_acc: 0.4700
Epoch 10/50
2000/2000 [==============================] - 68s - loss: 1.4397 - acc: 0.3700 - val_loss: 1.3519 - val_acc: 0.4225
Epoch 11/50
2000/2000 [==============================] - 69s - loss: 1.4385 - acc: 0.3730 - val_loss: 1.3192 - val_acc: 0.4588
Epoch 12/50
2000/2000 [==============================] - 68s - loss: 1.4166 - acc: 0.3835 - val_loss: 1.3134 - val_acc: 0.4625
Epoch 13/50
2000/2000 [==============================] - 68s - loss: 1.3905 - acc: 0.3950 - val_loss: 1.2745 - val_acc: 0.4900
Epoch 14/50
2000/2000 [==============================] - 69s - loss: 1.3660 - acc: 0.4170 - val_loss: 1.2979 - val_acc: 0.4850
Epoch 15/50
2000/2000 [==============================] - 68s - loss: 1.3460 - acc: 0.4330 - val_loss: 1.2881 - val_acc: 0.4613
Epoch 16/50
2000/2000 [==============================] - 67s - loss: 1.3578 - acc: 0.4065 - val_loss: 1.2653 - val_acc: 0.5025
Epoch 17/50
2000/2000 [==============================] - 67s - loss: 1.3395 - acc: 0.4395 - val_loss: 1.2780 - val_acc: 0.4612
Epoch 18/50
2000/2000 [==============================] - 67s - loss: 1.3016 - acc: 0.4445 - val_loss: 1.2897 - val_acc: 0.4288
Epoch 19/50
2000/2000 [==============================] - 66s - loss: 1.3117 - acc: 0.4465 - val_loss: 1.2112 - val_acc: 0.5187
Epoch 20/50
2000/2000 [==============================] - 66s - loss: 1.3090 - acc: 0.4370 - val_loss: 1.2184 - val_acc: 0.5350
Epoch 21/50
2000/2000 [==============================] - 67s - loss: 1.3164 - acc: 0.4460 - val_loss: 1.1616 - val_acc: 0.5300
Epoch 22/50
2000/2000 [==============================] - 67s - loss: 1.2727 - acc: 0.4560 - val_loss: 1.1996 - val_acc: 0.5137
Epoch 23/50
2000/2000 [==============================] - 67s - loss: 1.2712 - acc: 0.4570 - val_loss: 1.2146 - val_acc: 0.5025
Epoch 24/50
2000/2000 [==============================] - 69s - loss: 1.2349 - acc: 0.4900 - val_loss: 1.1637 - val_acc: 0.5000
Epoch 25/50
2000/2000 [==============================] - 69s - loss: 1.2548 - acc: 0.4760 - val_loss: 1.1838 - val_acc: 0.4850
Epoch 26/50
2000/2000 [==============================] - 71s - loss: 1.2249 - acc: 0.4700 - val_loss: 1.1460 - val_acc: 0.5250
Epoch 27/50
2000/2000 [==============================] - 68s - loss: 1.2038 - acc: 0.4950 - val_loss: 1.1542 - val_acc: 0.5125
Epoch 28/50
2000/2000 [==============================] - 67s - loss: 1.2142 - acc: 0.4835 - val_loss: 1.1494 - val_acc: 0.4850
Epoch 29/50
2000/2000 [==============================] - 67s - loss: 1.2113 - acc: 0.4910 - val_loss: 1.0757 - val_acc: 0.5475
Epoch 30/50
2000/2000 [==============================] - 69s - loss: 1.1665 - acc: 0.5125 - val_loss: 1.1004 - val_acc: 0.5138
Epoch 31/50
2000/2000 [==============================] - 69s - loss: 1.1752 - acc: 0.5240 - val_loss: 1.0650 - val_acc: 0.5475
Epoch 32/50
2000/2000 [==============================] - 69s - loss: 1.1714 - acc: 0.5140 - val_loss: 1.0479 - val_acc: 0.5738
Epoch 33/50
2000/2000 [==============================] - 69s - loss: 1.1531 - acc: 0.5145 - val_loss: 0.9994 - val_acc: 0.6238
Epoch 34/50
2000/2000 [==============================] - 68s - loss: 1.1444 - acc: 0.5100 - val_loss: 1.0680 - val_acc: 0.5663
Epoch 35/50
2000/2000 [==============================] - 71s - loss: 1.1250 - acc: 0.5280 - val_loss: 0.9983 - val_acc: 0.6138
Epoch 36/50
2000/2000 [==============================] - 70s - loss: 1.1075 - acc: 0.5395 - val_loss: 1.0099 - val_acc: 0.5825
Epoch 37/50
2000/2000 [==============================] - 69s - loss: 1.0858 - acc: 0.5595 - val_loss: 1.0045 - val_acc: 0.5788
Epoch 38/50
2000/2000 [==============================] - 68s - loss: 1.0691 - acc: 0.5435 - val_loss: 0.9908 - val_acc: 0.5975
Epoch 39/50
2000/2000 [==============================] - 69s - loss: 1.0888 - acc: 0.5525 - val_loss: 1.0119 - val_acc: 0.5800
Epoch 40/50
2000/2000 [==============================] - 70s - loss: 1.0953 - acc: 0.5365 - val_loss: 0.9584 - val_acc: 0.6175
Epoch 41/50
2000/2000 [==============================] - 69s - loss: 1.0849 - acc: 0.5550 - val_loss: 0.9566 - val_acc: 0.6012
Epoch 42/50
2000/2000 [==============================] - 69s - loss: 1.0539 - acc: 0.5550 - val_loss: 0.8984 - val_acc: 0.6237
Epoch 43/50
2000/2000 [==============================] - 71s - loss: 1.0559 - acc: 0.5560 - val_loss: 0.9424 - val_acc: 0.6163
Epoch 44/50
2000/2000 [==============================] - 70s - loss: 1.0355 - acc: 0.5570 - val_loss: 0.9344 - val_acc: 0.6200
Epoch 45/50
2000/2000 [==============================] - 68s - loss: 1.0558 - acc: 0.5630 - val_loss: 0.9287 - val_acc: 0.6450
Epoch 46/50
2000/2000 [==============================] - 68s - loss: 1.0297 - acc: 0.5805 - val_loss: 0.8494 - val_acc: 0.6713
Epoch 47/50
2000/2000 [==============================] - 71s - loss: 1.0347 - acc: 0.5750 - val_loss: 0.9238 - val_acc: 0.6125
Epoch 48/50
2000/2000 [==============================] - 68s - loss: 0.9969 - acc: 0.5965 - val_loss: 0.9231 - val_acc: 0.6088
Epoch 49/50
2000/2000 [==============================] - 69s - loss: 1.0266 - acc: 0.5700 - val_loss: 0.8736 - val_acc: 0.6513
Epoch 50/50
2000/2000 [==============================] - 71s - loss: 1.0065 - acc: 0.5795 - val_loss: 0.9538 - val_acc: 0.6000
Saved model to disk

akshat@akshat:/media/akshat/Akshat/Linux Backup/deep_learning/Consolidated_Data_Set/gesture_recognition_with_augmentation/codes$ python 2.\ ModelA1_training.py
Using Theano backend.
Using gpu device 0: GeForce GTX 960M (CNMeM is disabled, cuDNN not available)
Found 259867 images belonging to 5 classes.
Found 86562 images belonging to 5 classes.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           zeropadding2d_input_1[0][0]      
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 64, 222, 222)  4864        zeropadding2d_1[0][0]            
____________________________________________________________________________________________________
zeropadding2d_2 (ZeroPadding2D)  (None, 64, 224, 224)  0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           zeropadding2d_2[0][0]            
____________________________________________________________________________________________________
zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 110, 110)  102464      zeropadding2d_3[0][0]            
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 55, 55)    0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
zeropadding2d_4 (ZeroPadding2D)  (None, 64, 57, 57)    0           maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 55, 55)   73856       zeropadding2d_4[0][0]            
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 128, 27, 27)   0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
zeropadding2d_5 (ZeroPadding2D)  (None, 128, 29, 29)   0           maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 27, 27)   295168      zeropadding2d_5[0][0]            
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 256, 13, 13)   0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 43264)         0           maxpooling2d_4[0][0]             
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          44303360    flatten_1[0][0]                  
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 1024)          0           dense_1[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1024)          1049600     dropout_1[0][0]                  
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 1024)          0           dense_2[0][0]                    
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 5)             5125        dropout_2[0][0]                  
====================================================================================================
Total params: 45834437
____________________________________________________________________________________________________
Weights loaded
Epoch 1/50
2000/2000 [==============================] - 66s - loss: 0.9880 - acc: 0.5820 - val_loss: 0.9046 - val_acc: 0.6525
Epoch 2/50
2000/2000 [==============================] - 66s - loss: 0.9886 - acc: 0.5845 - val_loss: 0.8544 - val_acc: 0.6625
Epoch 3/50
2000/2000 [==============================] - 66s - loss: 1.0012 - acc: 0.5735 - val_loss: 0.8311 - val_acc: 0.6613
Epoch 4/50
2000/2000 [==============================] - 68s - loss: 0.9926 - acc: 0.6000 - val_loss: 0.8671 - val_acc: 0.6188
Epoch 5/50
2000/2000 [==============================] - 65s - loss: 0.9574 - acc: 0.6085 - val_loss: 0.7919 - val_acc: 0.6800
Epoch 6/50
2000/2000 [==============================] - 68s - loss: 0.9469 - acc: 0.6110 - val_loss: 0.8332 - val_acc: 0.6562
Epoch 7/50
2000/2000 [==============================] - 66s - loss: 0.9703 - acc: 0.5995 - val_loss: 0.8715 - val_acc: 0.6525
Epoch 8/50
2000/2000 [==============================] - 66s - loss: 0.9998 - acc: 0.5835 - val_loss: 0.8132 - val_acc: 0.6875
Epoch 9/50
2000/2000 [==============================] - 68s - loss: 0.9454 - acc: 0.6020 - val_loss: 0.7719 - val_acc: 0.7163
Epoch 10/50
2000/2000 [==============================] - 68s - loss: 0.9088 - acc: 0.6300 - val_loss: 0.7993 - val_acc: 0.6850
Epoch 11/50
2000/2000 [==============================] - 68s - loss: 0.9227 - acc: 0.6280 - val_loss: 0.7465 - val_acc: 0.6863
Epoch 12/50
2000/2000 [==============================] - 68s - loss: 0.9202 - acc: 0.6235 - val_loss: 0.7562 - val_acc: 0.6938
Epoch 13/50
2000/2000 [==============================] - 68s - loss: 0.8794 - acc: 0.6275 - val_loss: 0.7582 - val_acc: 0.6800
Epoch 14/50
2000/2000 [==============================] - 69s - loss: 0.8937 - acc: 0.6265 - val_loss: 0.7509 - val_acc: 0.7063
Epoch 15/50
2000/2000 [==============================] - 68s - loss: 0.8957 - acc: 0.6375 - val_loss: 0.8090 - val_acc: 0.6750
Epoch 16/50
2000/2000 [==============================] - 69s - loss: 0.8905 - acc: 0.6305 - val_loss: 0.7410 - val_acc: 0.7038
Epoch 17/50
2000/2000 [==============================] - 69s - loss: 0.8988 - acc: 0.6305 - val_loss: 0.7329 - val_acc: 0.7000
Epoch 18/50
2000/2000 [==============================] - 66s - loss: 0.8898 - acc: 0.6470 - val_loss: 0.7046 - val_acc: 0.7375
Epoch 19/50
2000/2000 [==============================] - 65s - loss: 0.8868 - acc: 0.6215 - val_loss: 0.7652 - val_acc: 0.7162
Epoch 20/50
2000/2000 [==============================] - 66s - loss: 0.8688 - acc: 0.6455 - val_loss: 0.7058 - val_acc: 0.7413
Epoch 21/50
2000/2000 [==============================] - 66s - loss: 0.8754 - acc: 0.6450 - val_loss: 0.7100 - val_acc: 0.7312
Epoch 22/50
2000/2000 [==============================] - 66s - loss: 0.8430 - acc: 0.6595 - val_loss: 0.7236 - val_acc: 0.7138
Epoch 23/50
2000/2000 [==============================] - 65s - loss: 0.8262 - acc: 0.6570 - val_loss: 0.7326 - val_acc: 0.6850
Epoch 24/50
2000/2000 [==============================] - 65s - loss: 0.8377 - acc: 0.6565 - val_loss: 0.6558 - val_acc: 0.7338
Epoch 25/50
2000/2000 [==============================] - 65s - loss: 0.8121 - acc: 0.6690 - val_loss: 0.6438 - val_acc: 0.7612
Epoch 26/50
2000/2000 [==============================] - 65s - loss: 0.8236 - acc: 0.6495 - val_loss: 0.6260 - val_acc: 0.7675
Epoch 27/50
2000/2000 [==============================] - 66s - loss: 0.8130 - acc: 0.6655 - val_loss: 0.6742 - val_acc: 0.7387
Epoch 28/50
2000/2000 [==============================] - 66s - loss: 0.7994 - acc: 0.6815 - val_loss: 0.7618 - val_acc: 0.6950
Epoch 29/50
2000/2000 [==============================] - 66s - loss: 0.7877 - acc: 0.6775 - val_loss: 0.6481 - val_acc: 0.7475
Epoch 30/50
2000/2000 [==============================] - 65s - loss: 0.7764 - acc: 0.6810 - val_loss: 0.6394 - val_acc: 0.7513
Epoch 31/50
2000/2000 [==============================] - 66s - loss: 0.7859 - acc: 0.6805 - val_loss: 0.6616 - val_acc: 0.7450
Epoch 32/50
2000/2000 [==============================] - 66s - loss: 0.7604 - acc: 0.6960 - val_loss: 0.6388 - val_acc: 0.7550
Epoch 33/50
2000/2000 [==============================] - 66s - loss: 0.7444 - acc: 0.6985 - val_loss: 0.5862 - val_acc: 0.7925
Epoch 34/50
2000/2000 [==============================] - 66s - loss: 0.7528 - acc: 0.7010 - val_loss: 0.6595 - val_acc: 0.7375
Epoch 35/50
2000/2000 [==============================] - 67s - loss: 0.7844 - acc: 0.6835 - val_loss: 0.5861 - val_acc: 0.7787
Epoch 36/50
2000/2000 [==============================] - 66s - loss: 0.7525 - acc: 0.6870 - val_loss: 0.6196 - val_acc: 0.7400
Epoch 37/50
2000/2000 [==============================] - 67s - loss: 0.7286 - acc: 0.7110 - val_loss: 0.6331 - val_acc: 0.7412
Epoch 38/50
2000/2000 [==============================] - 66s - loss: 0.7389 - acc: 0.6910 - val_loss: 0.5813 - val_acc: 0.7725
Epoch 39/50
2000/2000 [==============================] - 66s - loss: 0.7749 - acc: 0.6940 - val_loss: 0.5983 - val_acc: 0.8000
Epoch 40/50
2000/2000 [==============================] - 65s - loss: 0.7415 - acc: 0.7000 - val_loss: 0.5648 - val_acc: 0.8025
Epoch 41/50
2000/2000 [==============================] - 67s - loss: 0.7103 - acc: 0.7180 - val_loss: 0.5900 - val_acc: 0.7888
Epoch 42/50
2000/2000 [==============================] - 66s - loss: 0.7032 - acc: 0.7170 - val_loss: 0.5408 - val_acc: 0.7825
Epoch 43/50
2000/2000 [==============================] - 66s - loss: 0.7608 - acc: 0.6935 - val_loss: 0.5351 - val_acc: 0.8125
Epoch 44/50
2000/2000 [==============================] - 67s - loss: 0.7016 - acc: 0.7210 - val_loss: 0.5382 - val_acc: 0.7887
Epoch 45/50
2000/2000 [==============================] - 67s - loss: 0.7267 - acc: 0.7045 - val_loss: 0.5299 - val_acc: 0.8163
Epoch 46/50
2000/2000 [==============================] - 68s - loss: 0.7054 - acc: 0.7015 - val_loss: 0.5639 - val_acc: 0.7637
Epoch 47/50
2000/2000 [==============================] - 67s - loss: 0.7218 - acc: 0.7165 - val_loss: 0.5090 - val_acc: 0.8175
Epoch 48/50
2000/2000 [==============================] - 67s - loss: 0.6839 - acc: 0.7275 - val_loss: 0.4921 - val_acc: 0.8312
Epoch 49/50
2000/2000 [==============================] - 67s - loss: 0.6639 - acc: 0.7410 - val_loss: 0.5088 - val_acc: 0.8275
Epoch 50/50
2000/2000 [==============================] - 66s - loss: 0.6536 - acc: 0.7415 - val_loss: 0.5615 - val_acc: 0.7937
Saved model to disk

akshat@akshat:/media/akshat/Akshat/Linux Backup/deep_learning/Consolidated_Data_Set/gesture_recognition_with_augmentation/codes$ python 2.\ ModelA1_training.py
Using Theano backend.
Using gpu device 0: GeForce GTX 960M (CNMeM is disabled, cuDNN not available)
Found 259867 images belonging to 5 classes.
Found 86562 images belonging to 5 classes.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           zeropadding2d_input_1[0][0]      
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 64, 222, 222)  4864        zeropadding2d_1[0][0]            
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 64, 111, 111)  0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
zeropadding2d_2 (ZeroPadding2D)  (None, 64, 113, 113)  0           maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 109, 109)  102464      zeropadding2d_2[0][0]            
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 54, 54)    0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
zeropadding2d_3 (ZeroPadding2D)  (None, 64, 56, 56)    0           maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 54, 54)   73856       zeropadding2d_3[0][0]            
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 128, 27, 27)   0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
zeropadding2d_4 (ZeroPadding2D)  (None, 128, 29, 29)   0           maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 27, 27)   295168      zeropadding2d_4[0][0]            
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 256, 13, 13)   0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 43264)         0           maxpooling2d_4[0][0]             
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          44303360    flatten_1[0][0]                  
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 1024)          0           dense_1[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1024)          1049600     dropout_1[0][0]                  
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 1024)          0           dense_2[0][0]                    
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 5)             5125        dropout_2[0][0]                  
====================================================================================================
Total params: 45834437
____________________________________________________________________________________________________
Weights loaded
Epoch 1/50
2000/2000 [==============================] - 57s - loss: 0.6552 - acc: 0.7550 - val_loss: 0.5457 - val_acc: 0.7937
Epoch 2/50
2000/2000 [==============================] - 57s - loss: 0.6762 - acc: 0.7280 - val_loss: 0.4954 - val_acc: 0.8038
Epoch 3/50
2000/2000 [==============================] - 57s - loss: 0.6411 - acc: 0.7505 - val_loss: 0.4693 - val_acc: 0.8462
Epoch 4/50
2000/2000 [==============================] - 56s - loss: 0.6918 - acc: 0.7185 - val_loss: 0.4760 - val_acc: 0.8237
Epoch 5/50
2000/2000 [==============================] - 56s - loss: 0.6410 - acc: 0.7405 - val_loss: 0.5013 - val_acc: 0.8100
Epoch 6/50
2000/2000 [==============================] - 56s - loss: 0.6096 - acc: 0.7550 - val_loss: 0.4861 - val_acc: 0.8250
Epoch 7/50
2000/2000 [==============================] - 56s - loss: 0.6386 - acc: 0.7405 - val_loss: 0.5068 - val_acc: 0.8325
Epoch 8/50
2000/2000 [==============================] - 57s - loss: 0.6373 - acc: 0.7425 - val_loss: 0.4429 - val_acc: 0.8512
Epoch 9/50
2000/2000 [==============================] - 56s - loss: 0.6446 - acc: 0.7430 - val_loss: 0.4846 - val_acc: 0.8112
Epoch 10/50
2000/2000 [==============================] - 57s - loss: 0.6591 - acc: 0.7545 - val_loss: 0.4704 - val_acc: 0.8262
Epoch 11/50
2000/2000 [==============================] - 57s - loss: 0.6453 - acc: 0.7425 - val_loss: 0.4494 - val_acc: 0.8475
Epoch 12/50
2000/2000 [==============================] - 56s - loss: 0.6383 - acc: 0.7500 - val_loss: 0.4391 - val_acc: 0.8362
Epoch 13/50
2000/2000 [==============================] - 56s - loss: 0.6453 - acc: 0.7340 - val_loss: 0.4041 - val_acc: 0.8462
Epoch 14/50
2000/2000 [==============================] - 56s - loss: 0.6145 - acc: 0.7690 - val_loss: 0.4144 - val_acc: 0.8612
Epoch 15/50
2000/2000 [==============================] - 56s - loss: 0.6350 - acc: 0.7565 - val_loss: 0.4782 - val_acc: 0.8338
Epoch 16/50
2000/2000 [==============================] - 55s - loss: 0.6351 - acc: 0.7370 - val_loss: 0.4684 - val_acc: 0.8225
Epoch 17/50
2000/2000 [==============================] - 56s - loss: 0.6374 - acc: 0.7510 - val_loss: 0.4311 - val_acc: 0.8400
Epoch 18/50
2000/2000 [==============================] - 55s - loss: 0.6206 - acc: 0.7580 - val_loss: 0.4392 - val_acc: 0.8375
Epoch 19/50
2000/2000 [==============================] - 56s - loss: 0.6230 - acc: 0.7590 - val_loss: 0.3936 - val_acc: 0.8650
Epoch 20/50
2000/2000 [==============================] - 57s - loss: 0.5891 - acc: 0.7785 - val_loss: 0.4124 - val_acc: 0.8550
Epoch 21/50
2000/2000 [==============================] - 56s - loss: 0.5562 - acc: 0.7680 - val_loss: 0.4399 - val_acc: 0.8412
Epoch 22/50
2000/2000 [==============================] - 56s - loss: 0.6258 - acc: 0.7505 - val_loss: 0.4419 - val_acc: 0.8463
Epoch 23/50
2000/2000 [==============================] - 57s - loss: 0.6098 - acc: 0.7550 - val_loss: 0.4397 - val_acc: 0.8450
Epoch 24/50
2000/2000 [==============================] - 56s - loss: 0.5553 - acc: 0.7775 - val_loss: 0.4104 - val_acc: 0.8475
Epoch 25/50
2000/2000 [==============================] - 57s - loss: 0.5916 - acc: 0.7645 - val_loss: 0.4656 - val_acc: 0.8337
Epoch 26/50
2000/2000 [==============================] - 57s - loss: 0.5958 - acc: 0.7635 - val_loss: 0.4185 - val_acc: 0.8537
Epoch 27/50
2000/2000 [==============================] - 57s - loss: 0.5779 - acc: 0.7685 - val_loss: 0.3803 - val_acc: 0.8687
Epoch 28/50
2000/2000 [==============================] - 57s - loss: 0.5965 - acc: 0.7745 - val_loss: 0.4196 - val_acc: 0.8637
Epoch 29/50
2000/2000 [==============================] - 57s - loss: 0.5927 - acc: 0.7595 - val_loss: 0.3859 - val_acc: 0.8575
Epoch 30/50
2000/2000 [==============================] - 56s - loss: 0.5572 - acc: 0.7730 - val_loss: 0.3692 - val_acc: 0.8750
Epoch 31/50
2000/2000 [==============================] - 57s - loss: 0.5478 - acc: 0.7835 - val_loss: 0.4146 - val_acc: 0.8512
Epoch 32/50
2000/2000 [==============================] - 56s - loss: 0.5911 - acc: 0.7670 - val_loss: 0.3788 - val_acc: 0.8650
Epoch 33/50
2000/2000 [==============================] - 57s - loss: 0.5647 - acc: 0.7820 - val_loss: 0.3824 - val_acc: 0.8562
Epoch 34/50
2000/2000 [==============================] - 57s - loss: 0.5641 - acc: 0.7750 - val_loss: 0.3609 - val_acc: 0.8600
Epoch 35/50
2000/2000 [==============================] - 56s - loss: 0.5392 - acc: 0.7985 - val_loss: 0.4197 - val_acc: 0.8425
Epoch 36/50
2000/2000 [==============================] - 57s - loss: 0.5819 - acc: 0.7660 - val_loss: 0.3824 - val_acc: 0.8525
Epoch 37/50
2000/2000 [==============================] - 57s - loss: 0.5643 - acc: 0.7805 - val_loss: 0.3665 - val_acc: 0.8687
Epoch 38/50
2000/2000 [==============================] - 57s - loss: 0.5673 - acc: 0.7810 - val_loss: 0.3380 - val_acc: 0.8850
Epoch 39/50
2000/2000 [==============================] - 57s - loss: 0.5474 - acc: 0.7900 - val_loss: 0.3531 - val_acc: 0.8725
Epoch 40/50
2000/2000 [==============================] - 58s - loss: 0.5796 - acc: 0.7735 - val_loss: 0.4018 - val_acc: 0.8637
Epoch 41/50
2000/2000 [==============================] - 58s - loss: 0.5285 - acc: 0.7885 - val_loss: 0.3398 - val_acc: 0.8750
Epoch 42/50
2000/2000 [==============================] - 57s - loss: 0.5161 - acc: 0.7960 - val_loss: 0.3778 - val_acc: 0.8725
Epoch 43/50
2000/2000 [==============================] - 59s - loss: 0.4964 - acc: 0.8030 - val_loss: 0.3521 - val_acc: 0.8825
Epoch 44/50
2000/2000 [==============================] - 58s - loss: 0.5500 - acc: 0.7860 - val_loss: 0.3264 - val_acc: 0.9013
Epoch 45/50
2000/2000 [==============================] - 57s - loss: 0.4606 - acc: 0.8240 - val_loss: 0.2779 - val_acc: 0.8987
Epoch 46/50
2000/2000 [==============================] - 58s - loss: 0.5318 - acc: 0.7895 - val_loss: 0.3476 - val_acc: 0.8775
Epoch 47/50
2000/2000 [==============================] - 58s - loss: 0.4848 - acc: 0.8135 - val_loss: 0.3110 - val_acc: 0.8913
Epoch 48/50
2000/2000 [==============================] - 58s - loss: 0.5204 - acc: 0.8040 - val_loss: 0.3575 - val_acc: 0.8650
Epoch 49/50
2000/2000 [==============================] - 58s - loss: 0.5392 - acc: 0.8025 - val_loss: 0.3395 - val_acc: 0.8800
Epoch 50/50
2000/2000 [==============================] - 58s - loss: 0.5362 - acc: 0.7800 - val_loss: 0.3112 - val_acc: 0.9000
Saved model to disk
