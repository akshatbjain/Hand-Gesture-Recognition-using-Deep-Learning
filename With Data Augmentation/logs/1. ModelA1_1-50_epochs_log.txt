akshat@akshat:/media/akshat/Akshat/Linux Backup/deep_learning/Consolidated_Data_Set/gesture_recognition_with_augmentation/codes$ python 1.\ ModelA1_training.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 960M (CNMeM is disabled, cuDNN not available)
Found 262881 images belonging to 5 classes.
Found 87625 images belonging to 5 classes
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           zeropadding2d_input_1[0][0]      
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 64, 220, 220)  9472        zeropadding2d_1[0][0]            
____________________________________________________________________________________________________
zeropadding2d_2 (ZeroPadding2D)  (None, 64, 222, 222)  0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 64, 111, 111)  0           zeropadding2d_2[0][0]            
____________________________________________________________________________________________________
zeropadding2d_3 (ZeroPadding2D)  (None, 64, 113, 113)  0           maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 109, 109)  102464      zeropadding2d_3[0][0]            
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 64, 54, 54)    0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
zeropadding2d_4 (ZeroPadding2D)  (None, 64, 56, 56)    0           maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 52, 52)   204928      zeropadding2d_4[0][0]            
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 128, 26, 26)   0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
zeropadding2d_5 (ZeroPadding2D)  (None, 128, 28, 28)   0           maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 26, 26)   295168      zeropadding2d_5[0][0]            
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 256, 13, 13)   0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 43264)         0           maxpooling2d_4[0][0]             
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          44303360    flatten_1[0][0]                  
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 1024)          0           dense_1[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1024)          1049600     dropout_1[0][0]                  
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 1024)          0           dense_2[0][0]                    
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 5)             5125        dropout_2[0][0]                  
====================================================================================================
Total params: 45970117
____________________________________________________________________________________________________
Epoch 1/50
2000/2000 [==============================] - 145s - loss: 1.6095 - acc: 0.2180 - val_loss: 1.6114 - val_acc: 0.1850
Epoch 2/50
2000/2000 [==============================] - 124s - loss: 1.6103 - acc: 0.2035 - val_loss: 1.6072 - val_acc: 0.2163
Epoch 3/50
2000/2000 [==============================] - 125s - loss: 1.6089 - acc: 0.2015 - val_loss: 1.6071 - val_acc: 0.2237
Epoch 4/50
2000/2000 [==============================] - 127s - loss: 1.6088 - acc: 0.2065 - val_loss: 1.6101 - val_acc: 0.1850
Epoch 5/50
2000/2000 [==============================] - 121s - loss: 1.6088 - acc: 0.2025 - val_loss: 1.6080 - val_acc: 0.2112
Epoch 6/50
2000/2000 [==============================] - 119s - loss: 1.6092 - acc: 0.2145 - val_loss: 1.6110 - val_acc: 0.1962
Epoch 7/50
2000/2000 [==============================] - 117s - loss: 1.6104 - acc: 0.1880 - val_loss: 1.6068 - val_acc: 0.2575
Epoch 8/50
2000/2000 [==============================] - 121s - loss: 1.6090 - acc: 0.2065 - val_loss: 1.6083 - val_acc: 0.1925
Epoch 9/50
2000/2000 [==============================] - 115s - loss: 1.6087 - acc: 0.2155 - val_loss: 1.6065 - val_acc: 0.2487
Epoch 10/50
2000/2000 [==============================] - 115s - loss: 1.6086 - acc: 0.2170 - val_loss: 1.6089 - val_acc: 0.2337
Epoch 11/50
2000/2000 [==============================] - 109s - loss: 1.6093 - acc: 0.2075 - val_loss: 1.6105 - val_acc: 0.2275
Epoch 12/50
2000/2000 [==============================] - 105s - loss: 1.6083 - acc: 0.2065 - val_loss: 1.6066 - val_acc: 0.2075
Epoch 13/50
2000/2000 [==============================] - 104s - loss: 1.6081 - acc: 0.2115 - val_loss: 1.6076 - val_acc: 0.2025
Epoch 14/50
2000/2000 [==============================] - 106s - loss: 1.6079 - acc: 0.2190 - val_loss: 1.6066 - val_acc: 0.2125
Epoch 15/50
2000/2000 [==============================] - 106s - loss: 1.6090 - acc: 0.1975 - val_loss: 1.6078 - val_acc: 0.2437
Epoch 16/50
2000/2000 [==============================] - 105s - loss: 1.6074 - acc: 0.2210 - val_loss: 1.6089 - val_acc: 0.1950
Epoch 17/50
2000/2000 [==============================] - 100s - loss: 1.6071 - acc: 0.2185 - val_loss: 1.6074 - val_acc: 0.2550
Epoch 18/50
2000/2000 [==============================] - 103s - loss: 1.6094 - acc: 0.2005 - val_loss: 1.6070 - val_acc: 0.2400
Epoch 19/50
2000/2000 [==============================] - 100s - loss: 1.6060 - acc: 0.2365 - val_loss: 1.6095 - val_acc: 0.2400
Epoch 20/50
2000/2000 [==============================] - 99s - loss: 1.6080 - acc: 0.2165 - val_loss: 1.6036 - val_acc: 0.2250
Epoch 21/50
2000/2000 [==============================] - 92s - loss: 1.6071 - acc: 0.2225 - val_loss: 1.6067 - val_acc: 0.2075
Epoch 22/50
2000/2000 [==============================] - 92s - loss: 1.6061 - acc: 0.2200 - val_loss: 1.6066 - val_acc: 0.2000
Epoch 23/50
2000/2000 [==============================] - 89s - loss: 1.6071 - acc: 0.2245 - val_loss: 1.6053 - val_acc: 0.2387
Epoch 24/50
2000/2000 [==============================] - 89s - loss: 1.6066 - acc: 0.2375 - val_loss: 1.6042 - val_acc: 0.2638
Epoch 25/50
2000/2000 [==============================] - 95s - loss: 1.6031 - acc: 0.2305 - val_loss: 1.6027 - val_acc: 0.2425
Epoch 26/50
2000/2000 [==============================] - 92s - loss: 1.6075 - acc: 0.2300 - val_loss: 1.6042 - val_acc: 0.2538
Epoch 27/50
2000/2000 [==============================] - 91s - loss: 1.6068 - acc: 0.2190 - val_loss: 1.6005 - val_acc: 0.3087
Epoch 28/50
2000/2000 [==============================] - 93s - loss: 1.6067 - acc: 0.2425 - val_loss: 1.6013 - val_acc: 0.2712
Epoch 29/50
2000/2000 [==============================] - 91s - loss: 1.6059 - acc: 0.2250 - val_loss: 1.6068 - val_acc: 0.2275
Epoch 30/50
2000/2000 [==============================] - 93s - loss: 1.6067 - acc: 0.2265 - val_loss: 1.6065 - val_acc: 0.2437
Epoch 31/50
2000/2000 [==============================] - 95s - loss: 1.6056 - acc: 0.2310 - val_loss: 1.6045 - val_acc: 0.1975
Epoch 32/50
2000/2000 [==============================] - 94s - loss: 1.6054 - acc: 0.2380 - val_loss: 1.6017 - val_acc: 0.2387
Epoch 33/50
2000/2000 [==============================] - 97s - loss: 1.6057 - acc: 0.2270 - val_loss: 1.5989 - val_acc: 0.2613
Epoch 34/50
2000/2000 [==============================] - 100s - loss: 1.6027 - acc: 0.2360 - val_loss: 1.6008 - val_acc: 0.1950
Epoch 35/50
2000/2000 [==============================] - 104s - loss: 1.6035 - acc: 0.2340 - val_loss: 1.5946 - val_acc: 0.2437
Epoch 36/50
2000/2000 [==============================] - 108s - loss: 1.6053 - acc: 0.2200 - val_loss: 1.5957 - val_acc: 0.2662
Epoch 37/50
2000/2000 [==============================] - 111s - loss: 1.6023 - acc: 0.2350 - val_loss: 1.5971 - val_acc: 0.2862
Epoch 38/50
2000/2000 [==============================] - 114s - loss: 1.6011 - acc: 0.2470 - val_loss: 1.5921 - val_acc: 0.2613
Epoch 39/50
2000/2000 [==============================] - 87s - loss: 1.6022 - acc: 0.2265 - val_loss: 1.5927 - val_acc: 0.2962
Epoch 40/50
2000/2000 [==============================] - 86s - loss: 1.5986 - acc: 0.2505 - val_loss: 1.5920 - val_acc: 0.2225
Epoch 41/50
2000/2000 [==============================] - 87s - loss: 1.5977 - acc: 0.2335 - val_loss: 1.5944 - val_acc: 0.2500
Epoch 42/50
2000/2000 [==============================] - 85s - loss: 1.5970 - acc: 0.2485 - val_loss: 1.5839 - val_acc: 0.2675
Epoch 43/50
2000/2000 [==============================] - 85s - loss: 1.5967 - acc: 0.2485 - val_loss: 1.5826 - val_acc: 0.3138
Epoch 44/50
2000/2000 [==============================] - 86s - loss: 1.5956 - acc: 0.2460 - val_loss: 1.5862 - val_acc: 0.1987
Epoch 45/50
2000/2000 [==============================] - 85s - loss: 1.5927 - acc: 0.2585 - val_loss: 1.5807 - val_acc: 0.2562
Epoch 46/50
2000/2000 [==============================] - 85s - loss: 1.5932 - acc: 0.2480 - val_loss: 1.6014 - val_acc: 0.1850
Epoch 47/50
2000/2000 [==============================] - 87s - loss: 1.5849 - acc: 0.2640 - val_loss: 1.5744 - val_acc: 0.2837
Epoch 48/50
2000/2000 [==============================] - 86s - loss: 1.5905 - acc: 0.2555 - val_loss: 1.5781 - val_acc: 0.2700
Epoch 49/50
2000/2000 [==============================] - 87s - loss: 1.5845 - acc: 0.2600 - val_loss: 1.5726 - val_acc: 0.2650
Epoch 50/50
2000/2000 [==============================] - 85s - loss: 1.5801 - acc: 0.2640 - val_loss: 1.5745 - val_acc: 0.2325
Saved model to disk

